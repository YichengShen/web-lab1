<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CarSpeech - Yicheng</title>

    <!-- Font -->
    <link rel="preconnect" href="https://fonts.gstatic.com"> 
    <link href="https://fonts.googleapis.com/css2?family=Open+Sans&display=swap" rel="stylesheet">

    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-giJF6kkoqNQ00vy+HMDP7azOuL0xtbfIcaT9wjKHr8RbDVddVHyTfAAsrekwKmP1" crossorigin="anonymous">

    <style>
        body {
            font-family: 'Open Sans', sans-serif;
        }

        .name-header {
            padding: 150px 0 85px;
            background-color: #4e89f0;
        }

        header{
            font-weight: bolder;
            font-size: xx-large;
            padding: 10px 0 10px;
            text-decoration: underline;
        }
    </style>
</head>

<body>
    <header class="name-header text-white text-decoration-none" style="margin-bottom: 3%;">
        <div class="container text-center">
          <h1 style="font-weight: bolder;">CarSpeech</h1>
        </div>
    </header>

    <section>
        <div class="container">
            <div class="row">
                <div class="col-sm-10 mx-auto">
                    <ul>
                        <li><a href="index.html">Return to main page</a></li>
                    </ul>
                    <h5>Time</h5>
                    <p class="fw-lighter">Fall 2020</p>
                    <h5>Description</h5>
                    <p class="fw-lighter">
                        CarSpeech is a NLP project that trains CNN to recognize speech in noisy environment in cars. 
                        It focuses on comparing results of different ML models under various noise levels. Nowadays, 
                        people spend a lot of time in cars and they might need to use virtual assisstants, like Siri, 
                        when they are driving. So, virtual assisstants need to be powerful enough to understand human speech
                        under background noises. This project evaluates some of the ML models that can be used for speech recognition under different noise levels.
                    </p>
                    <h5>Links</h5>
                    <p><a href="https://yichengshen.github.io/car_speech/" target="_blank">Documentation</a></p>
                    <h5>Presentation of some results</h5>
                    <div class="row">
                        <div class="col-sm-4">
                            <figure>
                                <img src="assets/images/carspeech_table.png" class="img-fluid" alt="table">
                                <figcaption>
                                    The table reports the 10-fold cross validation accuracy of our best CNN model under different noise levels. 
                                    Note: 35U means 35 mph, windows down. 35U means 35 mph, windows up.
                                </figcaption>
                            </figure>
                        </div>
                        <div class="col-sm-8">
                            <figure>
                                <img src="assets/images/carspeech_boxplot.png" class="img-fluid" alt="boxplot">
                                <figcaption>
                                    The boxplot is generated using the data in the table on the left. 
                                    It shows that our model clearly achieved higher accuracy when the noise level is lower.
                                </figcaption>
                            </figure>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <footer class="py-3 bg-dark" style="margin-top: 6%;">
        <div class="container">
            <p class="m-0 text-center text-white">Copyright &copy; Yicheng Shen 2021</p>
        </div>
    </footer>
</body>
</html>